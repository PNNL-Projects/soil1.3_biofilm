{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc2cc0c-41fb-4a02-9d09-6e13ebffcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math, os, sys, copy, pickle\n",
    "from skimage import io, filters, restoration\n",
    "from skimage import morphology as morph\n",
    "import PIL\n",
    "from PIL import Image, ImageSequence, ImageEnhance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import glob\n",
    "import cv2\n",
    "import multipagetiff as mtif\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3922c64f-eaba-48a6-a16b-17425462483b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot(tif_files, try_denoise = False):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16,8), sharex=True, sharey=True)\n",
    "    for num, tif_file in enumerate(tif_files):\n",
    "        #print(tif_file, tif_file.rsplit(\".\", 1)[0][-1])\n",
    "        # num = int(tif_file.rsplit(\".\", 1)[0][-1])-1\n",
    "        im = Image.open(tif_file)\n",
    "        if denoise:\n",
    "            imarray = denoise(np.array(im))\n",
    "        else:\n",
    "            imarray = np.array(im)\n",
    "        # print(num, num//4, num%4)\n",
    "        axes[num//4, num%4].imshow(imarray)\n",
    "        axes[num//4, num%4].set_title(\"{}\".format(num+1))\n",
    "    plt.show()\n",
    "    # plt.colorbar()\n",
    "#     fig.subplots_adjust(right=0.85)\n",
    "#     cbar_ax = fig.add_axes([0.88, 0.15, 0.04, 0.7])\n",
    "#     fig.colorbar(im, cax=cbar_ax)\n",
    "def plot_oneZ(tif_files, z_pos = 0, z_num = 0):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16,8), sharex=True, sharey=True)\n",
    "    for tif_file in tif_files:\n",
    "        #print(tif_file, tif_file.rsplit(\".\", 1)[0][-1])\n",
    "        num = int(tif_file.rsplit(\".\", 1)[0][-1])-1\n",
    "        imgs = mtif.read_stack(tif_file)\n",
    "        if z_num != 0:\n",
    "            img = imgs[z_num - 1]\n",
    "        else:\n",
    "            img = imgs[math.floor(len(imgs) * z_pos)]\n",
    "        # print(num, num//4, num%4)\n",
    "        axes[num//4, num%4].imshow(img)\n",
    "        axes[num//4, num%4].set_title(\"{}\".format(num+1))\n",
    "    plt.show()\n",
    "def plot_single(img):\n",
    "    #print(tif_file, tif_file.rsplit(\".\", 1)[0][-1])\n",
    "    # im = Image.open(tif_file)\n",
    "    # img = np.array(im)\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    im_vis = ax.imshow(img)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im_vis, cax=cax)\n",
    "    plt.show()\n",
    "def flatten_plot(tif_files):\n",
    "    # fig, axes = plt.subplots(2,4, figsize=(16,8), sharex = True, sharey = True)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i, tif_file in enumerate(tif_files):\n",
    "        imgs = mtif.read_stack(tif_file)\n",
    "        plt.subplot(2,4,i+1)\n",
    "        img = mtif.flatten(imgs)\n",
    "        plt.imshow(img)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c517290",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize(img, min_range = 255, im_max = None, im_min = None, scale_to = 65535):\n",
    "    img_new = copy.deepcopy(img)\n",
    "    if im_max == None:\n",
    "        im_max = np.max(img)\n",
    "    if im_min == None:\n",
    "        im_min = np.min(img)\n",
    "    img_new = (img - im_min) / max([(im_max - im_min), min_range])\n",
    "    img_new = np.array(img_new * scale_to).astype(np.uint16)\n",
    "    return(img_new)\n",
    "def filter(img, min_thr = 0, threshold = None):\n",
    "    if threshold == None:\n",
    "        try:\n",
    "            threshold = max(filters.threshold_otsu(img), min_thr)\n",
    "        except:\n",
    "            threshold = img.min() + min_thr\n",
    "    mask = img > threshold\n",
    "    otsu_filtered = np.zeros_like(img)\n",
    "    otsu_filtered[mask] = img[mask]\n",
    "    return(otsu_filtered)\n",
    "def filter_z(imgz, min_thr = 0, threshold = None):\n",
    "    for i in range(len(imgz)):\n",
    "        imgz[i] = filter(imgz[i], min_thr, threshold)\n",
    "    return(imgz)\n",
    "def sub_bg_thr(img, min_thr = 0, threshold = None):\n",
    "    if threshold == None:\n",
    "        try:\n",
    "            threshold = max(filters.threshold_otsu(img), min_thr)\n",
    "        except:\n",
    "            threshold = img.min() + min_thr\n",
    "    img[img < threshold] = threshold\n",
    "    img = img - threshold\n",
    "    return(img)\n",
    "def sub_bg_thr_z(imgz, min_thr = 0, threshold = None):\n",
    "    for i in range(len(imgz)):\n",
    "        imgz[i] = sub_bg_thr(imgz[i], min_thr, threshold)\n",
    "    return(imgz)\n",
    "def threshold_z(imgz):\n",
    "    thresholds = [filters.threshold_otsu(img) for img in imgz]\n",
    "    return(max(thresholds))\n",
    "def threshold_all(imgs):\n",
    "    thresholds = [max([filters.threshold_otsu(img) for img in imgz]) for imgz in imgs]\n",
    "    return(max(thresholds)) \n",
    "def remove_background(img, rolling_ball_radius = 25):\n",
    "    background = restoration.rolling_ball(img, radius=rolling_ball_radius)\n",
    "    rolling_ball_filtered = img - background\n",
    "    return(rolling_ball_filtered)\n",
    "def remove_background_z(imgz, rolling_ball_radius = 25):\n",
    "    for i in range(len(imgz)):\n",
    "        imgz[i] = remove_background(imgz[i], rolling_ball_radius)\n",
    "    return(imgz)\n",
    "def denoise(img, min_thr = 0, rolling_ball_filtered = 25, threshold = None):\n",
    "    return(filter(remove_background(img, rolling_ball_filtered), threshold), min_thr)\n",
    "def denoise_z(imgz, min_thr = 0, rolling_ball_radius = 25, threshold = None):\n",
    "    imgz_denoised = copy.deepcopy(imgz)\n",
    "    try:\n",
    "        for i in range(len(imgz)):\n",
    "            imgz_denoised[i] = remove_background(imgz[i], rolling_ball_radius)\n",
    "        if threshold == None:\n",
    "            threshold = threshold_z(imgz_denoised)\n",
    "        for i in range(len(imgz)):\n",
    "            imgz_denoised[i] = filter(imgz_denoised[i], min_thr, threshold)\n",
    "    except:\n",
    "        # imgz_denoised = normalize(imgz)\n",
    "        print(\"Denoising failed, returning the original image\")\n",
    "    return(imgz_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524ce496",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sum_z(imgz):\n",
    "    try:\n",
    "        img_sum = np.sum(imgz, axis=0)\n",
    "    except:\n",
    "        img_sum = np.zeros_like(imgz)\n",
    "    return(img_sum)\n",
    "def ave_z(imgz):\n",
    "    try:\n",
    "        img_ave = np.mean(imgz, axis=0)\n",
    "    except:\n",
    "        img_ave = np.zero_like(imgz)\n",
    "    return(img_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a17e75d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def simple_stitch(imgs, seq_num = 4, hr_margin = 233, vu_margin = 0):\n",
    "    images = []\n",
    "    for i in range(seq_num):\n",
    "        img = imgs[i]\n",
    "        if i < 3:\n",
    "            images.append(img[:,:-hr_margin])\n",
    "        else:\n",
    "            images.append(img)\n",
    "    img1 = np.hstack(images)\n",
    "    images = []\n",
    "    for i in range(seq_num):\n",
    "        img = imgs[i+seq_num]\n",
    "        if i < 3:\n",
    "            images.append(img[:,:-hr_margin])\n",
    "        else:\n",
    "            images.append(img)\n",
    "    img2 = np.hstack(images)\n",
    "    im_h = np.vstack([img1[vu_margin:, :], img2[vu_margin:, :]])\n",
    "    return(im_h)\n",
    "def simple_stitch_z(imgs, z_num = None, seq_num = 4, hr_margin = 233, vu_margin = 0):\n",
    "    if z_num == None:\n",
    "        z_num = len(imgs[0])\n",
    "    stitched = []\n",
    "    for i in range(z_num):\n",
    "        images = [img[i] for img in imgs]\n",
    "        stitched.append(simple_stitch(images, seq_num, hr_margin, vu_margin))\n",
    "    return(np.array(stitched))\n",
    "\n",
    "def simple_stitch_alt(imgs, seq_num = 4, hr_margin = 233, vu_margin = 0):\n",
    "    images = []\n",
    "    for i in range(seq_num):\n",
    "        img = imgs[i * 2]\n",
    "        if i < 3:\n",
    "            images.append(img[:,:-hr_margin])\n",
    "        else:\n",
    "            images.append(img)\n",
    "    img1 = np.hstack(images)\n",
    "    images = []\n",
    "    for i in range(seq_num):\n",
    "        img = imgs[i * 2 + 1]\n",
    "        if i < 3:\n",
    "            images.append(img[:,:-hr_margin])\n",
    "        else:\n",
    "            images.append(img)\n",
    "    img2 = np.hstack(images)\n",
    "    im_h = np.vstack([img1[vu_margin:, :], img2[vu_margin:, :]])\n",
    "    return(im_h)\n",
    "def simple_stitch_z_alt(imgs, z_num = None, seq_num = 4, hr_margin = 233, vu_margin = 0):\n",
    "    if z_num == None:\n",
    "        z_num = len(imgs[0])\n",
    "    stitched = []\n",
    "    for i in range(z_num):\n",
    "        images = [img[i] for img in imgs]\n",
    "        stitched.append(simple_stitch_alt(images, seq_num, hr_margin, vu_margin))\n",
    "    return(np.array(stitched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153b3cab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sum_y(img):\n",
    "    img1d = np.sum(img, axis=0)\n",
    "    return(img1d)\n",
    "def slide_sum_y(img, slide_len = 100):\n",
    "    img1d = np.sum(img, axis=0)\n",
    "    img_slides = []\n",
    "    for i in range(0, len(img1d) - slide_len):\n",
    "        img_slides.append(np.sum(img1d[i:i+slide_len], axis=0))\n",
    "    return(np.array(img_slides))\n",
    "def get_pop_density(img1d):\n",
    "    pop_density = img1d/img1d.sum(axis=1, keepdims=True)\n",
    "    return(pop_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b33ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img):\n",
    "    img[img > 0] = 1\n",
    "    img = np.abs(1 - img)\n",
    "    return(img)\n",
    "def get_mask_inv(img):\n",
    "    img[img > 0] = 1\n",
    "    return(img)\n",
    "def mask_img(img, mask):\n",
    "    img[mask == 0] = 0\n",
    "    return(img)\n",
    "def simple_stitch_z_with_mask(imgs, mask, z_num = None, seq_num = 4, hr_margin = 233, vu_margin = 0):\n",
    "    if z_num == None:\n",
    "        z_num = len(imgs[0])\n",
    "    stitched = []\n",
    "    for i in range(z_num):\n",
    "        images = [img[i] for img in imgs]\n",
    "        stitched.append(mask_img(simple_stitch(images, seq_num, hr_margin, vu_margin), get_mask(mask)))\n",
    "    return(np.array(stitched))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5856e",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3616d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/Users/feng626/workspace/data/SoilSFA/spatial_interactions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3240482",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep3_dir = work_dir + \"/Activity_1.3_rep3_02.07.22_start\"\n",
    "rep3_img_dirs = [name for name in os.listdir(rep3_dir) if os.path.isdir(os.path.join(rep3_dir, name))] \n",
    "rep3_img_dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3240482",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep2_dir = work_dir + \"/Activity_1.3_rep2_12.13.21_start\"\n",
    "rep2_img_dirs = [name for name in os.listdir(rep2_dir) if os.path.isdir(os.path.join(rep2_dir, name))] \n",
    "rep2_img_dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9d3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_number = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca63db7",
   "metadata": {},
   "source": [
    "## Work on the rep3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stitch all the BF figures and keep z stacks\n",
    "# for chi, channel in enumerate(['w1SD BF', 'w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#     for dir in rep3_img_dirs:\n",
    "#         if dir == \"02.09.22_11AM_Chito5\" and chi != 0:\n",
    "#             continue\n",
    "#         img_dir = rep3_dir + '/' + dir \n",
    "#         tif_files = [img_dir + '/' + dir + '_1_' + channel +  '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "#         tif_files.sort()\n",
    "#         tif_file_new = img_dir + '/' + dir + '_1_{}_stitched.TIF'.format(channel)\n",
    "#         # if not os.path.isfile(tif_file_new):\n",
    "#         imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#         if chi == 0:\n",
    "#             imgzn = simple_stitch(imgs)\n",
    "#         else:\n",
    "#             imgzn = simple_stitch_z(imgs)\n",
    "#         io.imsave(tif_file_new, imgzn)\n",
    "#         # else:\n",
    "#         #     imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#         #     if chi == 0:\n",
    "#         #         imgzn = simple_stitch_alt(imgs)\n",
    "#         #     else:\n",
    "#         #         imgzn = simple_stitch_z_alt(imgs)\n",
    "#         #     io.imsave(tif_file_new[:-4] + \"_alt.TIF\", imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54bb50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chi, channel in enumerate(['w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#     for dir in rep3_img_dirs:\n",
    "#         if dir == \"02.09.22_11AM_Chito5\":\n",
    "#             continue\n",
    "#         img_dir = rep3_dir + '/' + dir \n",
    "#         for i in range(patch_number):\n",
    "#             tif_file = img_dir + '/' + dir + '_1_{}_s{}.TIF'.format(channel, i+1)\n",
    "#             tif_file_new = img_dir + '/' + dir + '_1_{}_s{}_wo_bg.TIF'.format(channel, i+1)\n",
    "#             if not os.path.isfile(tif_file_new):\n",
    "#                 imgz = io.imread(tif_file)\n",
    "#                 imgzn = remove_background_z(imgz)\n",
    "#                 io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df230b2-6cc2-4c2a-8c60-1a1add3ebd0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_thrs = [75, 250, 250]\n",
    "global_thr = 255\n",
    "min_thr = 32\n",
    "result_dir = \"./results_rep3\"\n",
    "counter = 0\n",
    "for dir in rep3_img_dirs:\n",
    "    # if dir == \"02.09.22_11AM_Chito5\":\n",
    "        # continue\n",
    "    img_dir = rep3_dir + '/' + dir \n",
    "    all_channels = []\n",
    "    for chi, channel in enumerate(['w4SD RFP', 'w3SD GFP', 'w2SD DAPI']):\n",
    "        counter += 1\n",
    "        masked_file = img_dir + '/' + dir + '_1_w1SD BF_stitched_mask.tif'\n",
    "        tif_files = [img_dir + '/' + dir + '_1_' + channel +  '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "        tif_files.sort()\n",
    "        new_tif_file = img_dir + '/' + dir + '_1_{}_wo_bg_stichted_masked.TIF'.format(channel)\n",
    "        new_summed_tif_file = img_dir + '/' + dir + '_1_{}_wo_bg_stichted_masked_summed.TIF'.format(channel)\n",
    "        summed_csv_file = result_dir + '/' + dir + '_1_{}_wo_bg_stichted_sub_thr_masked_summed.csv'.format(channel)\n",
    "\n",
    "        imgs_mask = get_mask(io.imread(masked_file))\n",
    "        imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "        imgs_filtered = [denoise_z(img, min_thr) for img in imgs]\n",
    "        # imgs_sub_bg = [sub_bg_thr_z(img, global_thr) for img in imgs]\n",
    "        # imgs_sub_bg = [normalize(img) for img in imgs_sub_bg]\n",
    "        # imgs_filtered = [denoise_z(img) for img in imgs_sub_bg]\n",
    "        # imgs_filtered = [filter_z(img) for img in imgs_norm]\n",
    "        # imgs_filtered = [remove_background_z(img) for img in imgs]\n",
    "        # imgs_filtered = [filter_z(img, global_thrs[chi]) for img in imgs_norm]\n",
    "        imgs_stitched_z = simple_stitch_z(imgs_filtered)\n",
    "        imgs_stitched_z = denoise_z(imgs_stitched_z, min_thr)\n",
    "        # masked_img_z = imgs_stitched_z\n",
    "        masked_img_z = np.array([mask_img(imgs_stitched_zi, imgs_mask) for imgs_stitched_zi in imgs_stitched_z])\n",
    "        masked_img_z = denoise_z(masked_img_z, min_thr)\n",
    "        tifffile.imsave(new_tif_file, masked_img_z)\n",
    "\n",
    "        # imgi_summed = [sum_z(img) for img in imgs_filtered]\n",
    "        # imgi_summed = [denoise(img) for img in imgi_summed]\n",
    "        # imgi_summed = [filter(img) for img in imgi_summed]\n",
    "        # imgi_summed = [filter(img, global_thrs[chi]) for img in imgi_summed]\n",
    "        # imgs_summed = simple_stitch(imgi_summed)\n",
    "        imgs_summed = sum_z(masked_img_z)\n",
    "        imgs_summed = denoise(imgs_summed, min_thr)\n",
    "        # imgs_summed = filter(imgs_summed)\n",
    "        # imgs_summed = filter(imgs_summed, global_thrs[chi])\n",
    "        imgs_summed = mask_img(imgs_summed, imgs_mask)\n",
    "        # imgs_summed = denoise(imgs_summed)\n",
    "        img_to_merge = normalize(imgs_summed)\n",
    "        # img_to_merge = imgs_summed\n",
    "        io.imsave(new_summed_tif_file, img_to_merge)\n",
    "        np.savetxt(summed_csv_file, img_to_merge, delimiter=',')\n",
    "\n",
    "        all_channels.append(img_to_merge)\n",
    "        \n",
    "    combined_img = np.transpose(all_channels, (1,2,0))\n",
    "        \n",
    "    output = result_dir + '/' + dir + '_1_combined_masked_normalized'\n",
    "    img_out = output + '.TIF'\n",
    "    pkl_out = output + '.pkl'\n",
    "    plot_out = output + '_1d.png'\n",
    "        \n",
    "    with open(pkl_out, 'wb') as f:\n",
    "        pickle.dump(combined_img, f)\n",
    "        \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.imshow(combined_img)\n",
    "    plt.savefig(img_out, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    pop_den = get_pop_density(slide_sum_y(combined_img, combined_img.shape[1]//20))\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i in range(3):\n",
    "        plt.plot(range(len(pop_den)), pop_den[:,i], color = colors[i], linewidth=3)\n",
    "    # plt.plot(range(len(pop_den)), pop_den, linewidth=2)\n",
    "    plt.savefig(plot_out, dpi=300)\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca63db7",
   "metadata": {},
   "source": [
    "## Work on the rep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c0f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stitch all the BF figures and keep z stacks\n",
    "# for chi, channel in enumerate(['w1SD BF', 'w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#     for dir in rep2_img_dirs:\n",
    "#         img_dir = rep2_dir + '/' + dir \n",
    "#         tif_files = [img_dir + '/' + dir + '_1_' + channel +  '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "#         tif_files.sort()\n",
    "#         tif_file_new = img_dir + '/' + dir + '_1_{}_stitched.TIF'.format(channel)\n",
    "#         # if not os.path.isfile(tif_file_new):\n",
    "#         imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#         if chi == 0:\n",
    "#             imgzn = simple_stitch(imgs)\n",
    "#         else:\n",
    "#             imgzn = simple_stitch_z(imgs)\n",
    "#         io.imsave(tif_file_new, imgzn)\n",
    "#         # else:\n",
    "#         #     imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#         #     if chi == 0:\n",
    "#         #         imgzn = simple_stitch_alt(imgs)\n",
    "#         #     else:\n",
    "#         #         imgzn = simple_stitch_z_alt(imgs)\n",
    "#         #     io.imsave(tif_file_new[:-4] + \"_alt.TIF\", imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54bb50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chi, channel in enumerate(['w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#     for dir in rep2_img_dirs:\n",
    "#         img_dir = rep2_dir + '/' + dir \n",
    "#         for i in range(patch_number):\n",
    "#             tif_file = img_dir + '/' + dir + '_1_{}_s{}.TIF'.format(channel, i+1)\n",
    "#             tif_file_new = img_dir + '/' + dir + '_1_{}_s{}_wo_bg.TIF'.format(channel, i+1)\n",
    "#             if not os.path.isfile(tif_file_new):\n",
    "#                 imgz = io.imread(tif_file)\n",
    "#                 imgzn = remove_background_z(imgz)\n",
    "#                 io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df230b2-6cc2-4c2a-8c60-1a1add3ebd0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "channel_thrs = [75, 250, 250]\n",
    "global_thr = 255\n",
    "min_thr = 32\n",
    "result_dir = \"./results_rep2\"\n",
    "counter = 0\n",
    "for dir in rep2_img_dirs:\n",
    "    img_dir = rep2_dir + '/' + dir \n",
    "    all_channels = []\n",
    "    for chi, channel in enumerate(['w4SD RFP', 'w3SD GFP', 'w2SD DAPI']):\n",
    "        counter += 1\n",
    "        masked_file = img_dir + '/' + dir + '_1_w1SD BF_stitched_mask.tif'\n",
    "        tif_files = [img_dir + '/' + dir + '_1_' + channel +  '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "        tif_files.sort()\n",
    "        new_tif_file = img_dir + '/' + dir + '_1_{}_wo_bg_stichted_masked.TIF'.format(channel)\n",
    "        new_summed_tif_file = img_dir + '/' + dir + '_1_{}_wo_bg_stichted_masked_summed.TIF'.format(channel)\n",
    "        summed_csv_file = result_dir + '/' + dir + '_1_{}_wo_bg_stichted_sub_thr_masked_summed.csv'.format(channel)\n",
    "\n",
    "        imgs_mask = get_mask(io.imread(masked_file))\n",
    "        imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "        imgs_filtered = [denoise_z(img, min_thr) for img in imgs]\n",
    "        # imgs_sub_bg = [sub_bg_thr_z(img, global_thr) for img in imgs]\n",
    "        # imgs_sub_bg = [normalize(img) for img in imgs_sub_bg]\n",
    "        # imgs_filtered = [denoise_z(img) for img in imgs_sub_bg]\n",
    "        # imgs_filtered = [remove_background_z(img) for img in imgs]\n",
    "        # imgs_filtered = [filter_z(img) for img in imgs_norm]\n",
    "        # imgs_filtered = [filter_z(img, global_thrs[chi]) for img in imgs_norm]\n",
    "        imgs_stitched_z = simple_stitch_z(imgs_filtered)\n",
    "        imgs_stitched_z = denoise_z(imgs_stitched_z, min_thr)\n",
    "        # masked_img_z = imgs_stitched_z\n",
    "        masked_img_z = np.array([mask_img(imgs_stitched_zi, imgs_mask) for imgs_stitched_zi in imgs_stitched_z])\n",
    "        masked_img_z = denoise_z(masked_img_z, min_thr)\n",
    "        tifffile.imsave(new_tif_file, masked_img_z)\n",
    "\n",
    "        # imgi_summed = [sum_z(img) for img in imgs_filtered]\n",
    "        # imgi_summed = [denoise(img) for img in imgi_summed]\n",
    "        # imgi_summed = [filter(img) for img in imgi_summed]\n",
    "        # imgi_summed = [filter(img, global_thrs[chi]) for img in imgi_summed]\n",
    "        # imgs_summed = simple_stitch(imgi_summed)\n",
    "        imgs_summed = sum_z(masked_img_z)\n",
    "        imgs_summed = denoise(imgs_summed, min_thr)\n",
    "        # imgs_summed = filter(imgs_summed)\n",
    "        # imgs_summed = filter(imgs_summed, global_thrs[chi])\n",
    "        imgs_summed = mask_img(imgs_summed, imgs_mask)\n",
    "        # imgs_summed = denoise(imgs_summed)\n",
    "        img_to_merge = normalize(imgs_summed)\n",
    "        # img_to_merge = imgs_summed\n",
    "        io.imsave(new_summed_tif_file, img_to_merge)\n",
    "        np.savetxt(summed_csv_file, img_to_merge, delimiter=',')\n",
    "\n",
    "        all_channels.append(img_to_merge)\n",
    "        \n",
    "    combined_img = np.transpose(all_channels, (1,2,0))\n",
    "        \n",
    "    output = result_dir + '/' + dir + '_1_combined_masked_normalized'\n",
    "    img_out = output + '.TIF'\n",
    "    pkl_out = output + '.pkl'\n",
    "    plot_out = output + '_1d.png'\n",
    "        \n",
    "    with open(pkl_out, 'wb') as f:\n",
    "        pickle.dump(combined_img, f)\n",
    "        \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.imshow(combined_img)\n",
    "    plt.savefig(img_out, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    pop_den = get_pop_density(slide_sum_y(combined_img, combined_img.shape[1]//20))\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i in range(3):\n",
    "        plt.plot(range(len(pop_den)), pop_den[:,i], color = colors[i], linewidth=3)\n",
    "    # plt.plot(range(len(pop_den)), pop_den, linewidth=2)\n",
    "    plt.savefig(plot_out, dpi=300)\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24810f",
   "metadata": {},
   "source": [
    "## Get background thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3537f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = \"/Users/feng626/workspace/data/SoilSFA/spatial_interactions/02.07.22_NoCellsCtrl\"\n",
    "# dir = \"02.07.22_NoCellsCtrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4bddbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/r7fd8dvd1b53ns6wtty0dhjs1g0xsn/T/ipykernel_1445/968577506.py:12: UserWarning: /Users/feng626/workspace/data/SoilSFA/spatial_interactions/02.07.22_NoCellsCtrl/02.07.22_NoCellsCtrl_1_w2SD DAPI_stitched_masked.TIF is a low contrast image\n",
      "  io.imsave(tif_file_new, imgzn)\n",
      "/var/folders/8b/r7fd8dvd1b53ns6wtty0dhjs1g0xsn/T/ipykernel_1445/968577506.py:12: UserWarning: /Users/feng626/workspace/data/SoilSFA/spatial_interactions/02.07.22_NoCellsCtrl/02.07.22_NoCellsCtrl_1_w3SD GFP_stitched_masked.TIF is a low contrast image\n",
      "  io.imsave(tif_file_new, imgzn)\n",
      "/var/folders/8b/r7fd8dvd1b53ns6wtty0dhjs1g0xsn/T/ipykernel_1445/968577506.py:12: UserWarning: /Users/feng626/workspace/data/SoilSFA/spatial_interactions/02.07.22_NoCellsCtrl/02.07.22_NoCellsCtrl_1_w4SD RFP_stitched_masked.TIF is a low contrast image\n",
      "  io.imsave(tif_file_new, imgzn)\n"
     ]
    }
   ],
   "source": [
    "# bg_max = []\n",
    "# imgzns = []\n",
    "# mask_file = img_dir + '/' + dir + '_1_w1SD BF_stitched_mask.tif'\n",
    "# mask = io.imread(mask_file)\n",
    "# for chi, channel in enumerate(['w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#     tif_files = glob.glob(img_dir + '/' + dir + '_1_{}_s*.TIF'.format(channel))\n",
    "#     tif_files.sort()\n",
    "#     tif_file_new = img_dir + '/' + dir + '_1_{}_stitched_masked.TIF'.format(channel)\n",
    "#     imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#     imgzn = simple_stitch_z_with_mask(imgs, mask)\n",
    "#     bg_max.append(np.nanmax(imgzn))\n",
    "#     io.imsave(tif_file_new, imgzn)\n",
    "#     imgzns.append(imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04cd738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[459, 555, 7151]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24810f",
   "metadata": {},
   "source": [
    "## Subtract backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/feng626/workspace/data/SoilSFA/spatial_interactions/Activity_1.3_rep1_11.18.21_start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for carbon in [\"Chitin\", \"Chito5\", \"Nag\"]:\n",
    "#     time_dir = image_dir + '/' + carbon \n",
    "#     timepoints = [name for name in os.listdir(time_dir) if os.path.isdir(os.path.join(time_dir, name))] \n",
    "#     timepoints.sort()\n",
    "#     for timepoint in timepoints:\n",
    "#         all_channels = []\n",
    "#         for chi, channel in enumerate(['w2SD DAPI', 'w3SD GFP', 'w4SD RFP']):\n",
    "#             for i in range(patch_number):\n",
    "#                 tif_file = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_s{}.TIF'.format(channel, i+1)\n",
    "#                 tif_file_new = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_s{}_wo_bg.TIF'.format(channel, i+1)\n",
    "#                 imgz = io.imread(tif_file)\n",
    "#                 imgzn = remove_background_z(imgz)\n",
    "#                 io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stitch all the BF figures and keep z stacks\n",
    "# for carbon in [\"Chitin\", \"Chito5\", \"Nag\"]:\n",
    "#     time_dir = image_dir + '/' + carbon \n",
    "#     timepoints = [name for name in os.listdir(time_dir) if os.path.isdir(os.path.join(time_dir, name))] \n",
    "#     timepoints.sort()\n",
    "#     for timepoint in timepoints:\n",
    "#         all_channels = []\n",
    "#         channel = \"w1SD BF\"\n",
    "#         tif_files = [image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_\" + channel + \"_s\" + str(i+1) + \".TIF' for i in range(patch_number)]\n",
    "#         tif_files.sort()\n",
    "#         tif_file_new = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_stitched.TIF'.format(channel)\n",
    "#         imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#         imgzn = simple_stitch(imgs)\n",
    "#         io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e938223",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # Stitch all the figures and keep z stacks\n",
    "# for carbon in [\"Chitin\", \"Chito5\", \"Nag\"]:\n",
    "#     time_dir = image_dir + '/' + carbon \n",
    "#     timepoints = [name for name in os.listdir(time_dir) if os.path.isdir(os.path.join(time_dir, name))] \n",
    "#     timepoints.sort()\n",
    "#     for timepoint in timepoints:\n",
    "#         all_channels = []\n",
    "#         for chi, channel in enumerate(['w4SD RFP', 'w3SD GFP', 'w2SD DAPI']):\n",
    "#             # tif_files = glob.glob(image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_s*_wo_bg.TIF'.format(channel))\n",
    "#             tif_files = [image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_\" + channel + \"_s\" + str(i) + \"_wo_bg.TIF' for i in range(1,patch_number+1)]\n",
    "#             tif_files.sort()\n",
    "#             # print(tif_files)\n",
    "#             tif_file_new = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_wo_bg_stitched.TIF'.format(channel)\n",
    "#             imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#             imgzn = simple_stitch_z(imgs)\n",
    "#             io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e938223",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # Stitch all the figures and keep z stacks\n",
    "# for carbon in [\"Chitin\", \"Chito5\", \"Nag\"]:\n",
    "#     time_dir = image_dir + '/' + carbon \n",
    "#     timepoints = [name for name in os.listdir(time_dir) if os.path.isdir(os.path.join(time_dir, name))] \n",
    "#     timepoints.sort()\n",
    "#     for timepoint in timepoints:\n",
    "#         all_channels = []\n",
    "#         for chi, channel in enumerate(['w1SD BF', 'w4SD RFP', 'w3SD GFP', 'w2SD DAPI']):\n",
    "#             tif_files = [image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_' + channel + '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "#             tif_files.sort()\n",
    "#             # print(tif_files)\n",
    "#             tif_file_new = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_stitched.TIF'.format(channel)\n",
    "#             imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "#             if chi == 0:\n",
    "#                 imgzn = simple_stitch(imgs)\n",
    "#             else:\n",
    "#                 imgzn = simple_stitch_z(imgs)\n",
    "#             io.imsave(tif_file_new, imgzn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad860d",
   "metadata": {},
   "source": [
    "## Merge masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df230b2-6cc2-4c2a-8c60-1a1add3ebd0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_thrs = [75, 250, 250]\n",
    "global_thr = 255\n",
    "min_thr = 32\n",
    "counter = 0\n",
    "for carbon in [\"Chitin\", \"Chito5\", \"Nag\"]:\n",
    "# for carbon, timepoints in zip([\"Chitin\", \"Chito5\", \"Nag\"], [[\"11.22.21_17\"], [\"11.22.21_16\"], [\"11.22.21_15\"]]):\n",
    "    time_dir = image_dir + '/' + carbon \n",
    "    timepoints = [name for name in os.listdir(time_dir) if os.path.isdir(os.path.join(time_dir, name))] \n",
    "    timepoints.sort()\n",
    "    for timepoint in timepoints:\n",
    "        all_channels = []\n",
    "        for chi, channel in enumerate(['w4SD RFP', 'w3SD GFP', 'w2SD DAPI']):\n",
    "            counter += 1\n",
    "            masked_file = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_w1SD BF_stitched_MASK.tif'\n",
    "            tif_files = [image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_' + channel + '_s' + str(i+1) + '.TIF' for i in range(patch_number)]\n",
    "            tif_files.sort()\n",
    "            new_tif_file = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_wo_bg_stichted_masked.TIF'.format(channel)\n",
    "            new_summed_tif_file = image_dir + '/' + carbon + '/' + timepoint + '/' + timepoint + '_' + carbon + '_1_{}_wo_bg_stichted_masked_summed.TIF'.format(channel)\n",
    "            summed_csv_file = './results_rep1/' + timepoint + '_' + carbon + '_1_{}_wo_bg_stichted_sub_thr_masked_summed.csv'.format(channel)\n",
    "\n",
    "            imgs_mask = get_mask(io.imread(masked_file))\n",
    "            imgs = [io.imread(tif_file) for tif_file in tif_files]\n",
    "            imgs_filtered = [denoise_z(img, min_thr) for img in imgs]\n",
    "            # imgs_filtered = [filter_z(img) for img in imgs]\n",
    "            # imgs_sub_bg = [sub_bg_thr_z(img, global_thr) for img in imgs]\n",
    "            # imgs_sub_bg = [normalize(img) for img in imgs_sub_bg]\n",
    "            # imgs_filtered = [denoise_z(img) for img in imgs_sub_bg]\n",
    "            # imgs_filtered = [remove_background_z(img) for img in imgs]\n",
    "            # imgs_filtered = [filter_z(img) for img in imgs_norm]\n",
    "            # imgs_filtered = [filter_z(img, global_thrs[chi]) for img in imgs_norm]\n",
    "            imgs_stitched_z = simple_stitch_z(imgs_filtered)\n",
    "            imgs_stitched_z = denoise_z(imgs_stitched_z, min_thr)\n",
    "            # masked_img_z = imgs_stitched_z\n",
    "            masked_img_z = np.array([mask_img(imgs_stitched_zi, imgs_mask) for imgs_stitched_zi in imgs_stitched_z])\n",
    "            masked_img_z = denoise_z(masked_img_z, min_thr)\n",
    "            tifffile.imsave(new_tif_file, masked_img_z)\n",
    "    \n",
    "            # imgi_summed = [sum_z(img) for img in imgs_filtered]\n",
    "            # imgi_summed = [denoise(img) for img in imgi_summed]\n",
    "            # imgi_summed = [filter(img) for img in imgi_summed]\n",
    "            # imgi_summed = [filter(img, global_thrs[chi]) for img in imgi_summed]\n",
    "            # imgs_summed = simple_stitch(imgi_summed)\n",
    "            imgs_summed = sum_z(masked_img_z)\n",
    "            imgs_summed = denoise(imgs_summed, min_thr)\n",
    "            # imgs_summed = filter(imgs_summed)\n",
    "            # imgs_summed = filter(imgs_summed, global_thrs[chi])\n",
    "            imgs_summed = mask_img(imgs_summed, imgs_mask)\n",
    "            # imgs_summed = denoise(imgs_summed)\n",
    "            img_to_merge = normalize(imgs_summed)\n",
    "            # img_to_merge = imgs_summed\n",
    "            io.imsave(new_summed_tif_file, img_to_merge)\n",
    "            np.savetxt(summed_csv_file, img_to_merge, delimiter=',')\n",
    "    \n",
    "            all_channels.append(img_to_merge)\n",
    "            \n",
    "        combined_img = np.transpose(all_channels, (1,2,0))\n",
    "            \n",
    "        output = result_dir + '/' + dir + '_1_combined_masked_normalized'\n",
    "        img_out = output + '.TIF'\n",
    "        pkl_out = output + '.pkl'\n",
    "        plot_out = output + '_1d.png'\n",
    "            \n",
    "        with open(pkl_out, 'wb') as f:\n",
    "            pickle.dump(combined_img, f)\n",
    "            \n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.imshow(combined_img)\n",
    "        plt.savefig(img_out, dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "        pop_den = get_pop_density(slide_sum_y(combined_img, combined_img.shape[1]//20))\n",
    "        colors = ['red', 'green', 'blue']\n",
    "        plt.figure(figsize=(16,8))\n",
    "        for i in range(3):\n",
    "            plt.plot(range(len(pop_den)), pop_den[:,i], color = colors[i], linewidth=3)\n",
    "        # plt.plot(range(len(pop_den)), pop_den, linewidth=2)\n",
    "        plt.savefig(plot_out, dpi=300)\n",
    "        # plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36a541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
